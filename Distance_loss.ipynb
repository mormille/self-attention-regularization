{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Optional, List\n",
    "\n",
    "from fastai.distributed import *\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as Tensor\n",
    "from torch import nn, Tensor\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from models.utils.distance_loss import *\n",
    "from models.utils.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 256\n",
    "W= 256\n",
    "bs = 10\n",
    "gd = 16\n",
    "\n",
    "transform = T.Compose([\n",
    "T.Resize((H,W)),\n",
    "T.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(width=256, height=256, grid_l=16):\n",
    "\n",
    "    w = width\n",
    "    h = height\n",
    "    qt_hor_grids = w//grid_l\n",
    "    qt_ver_grids = h//grid_l\n",
    "    qtd_grids = qt_hor_grids*qt_ver_grids\n",
    "    c = 0\n",
    "    grids = []\n",
    "    for i in range(qtd_grids):\n",
    "        hor_pos = i//qt_hor_grids\n",
    "        ver_pos = c\n",
    "        c = c+1\n",
    "        grid = [hor_pos,ver_pos]\n",
    "        grids.append(grid)\n",
    "        if c == qt_ver_grids:\n",
    "            c=0\n",
    "    #gd = torch.tensor(np.array(grids))\n",
    "    dist_grid = []\n",
    "    for g in range(len(grids)):\n",
    "        dist_pair_list = []\n",
    "        for n in range(len(grids)):\n",
    "            dist_pair_list.append(distance.cityblock(grids[g], grids[n]))\n",
    "        dist_grid.append(dist_pair_list)\n",
    "\n",
    "    dist_matrix = torch.tensor(np.array(dist_grid))\n",
    "\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = distance_matrix()\n",
    "dist_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty_weights(dist_matrix, penalty_factor=\"2\", alpha=4, beta=500, gamma=0.1):\n",
    "    if penalty_factor == \"1\":\n",
    "        high = (dist_matrix.max(0, keepdim=True)[0][0]+1).reshape(256,1)\n",
    "        pf_matrix = torch.div((dist_matrix+gamma),high)\n",
    "        return pf_matrix\n",
    "    if penalty_factor == \"2\":\n",
    "        high = (dist_matrix.max(0, keepdim=True)[0][0]).reshape(256,1)/alpha\n",
    "        a = torch.sub(dm,high)\n",
    "        pf_matrix = torch.div(a,torch.sqrt(torch.square(a)+beta))\n",
    "        return pf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = penalty_weights(dist_matrix)\n",
    "pf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty_matrix(bs, width=256, height=256, grid_l=16, penalty_factor=\"2\", alpha=4, beta=500, gamma=0.1):\n",
    "    dist_matrix = distance_matrix(width, height, grid_l)\n",
    "    pf = penalty_weights(dist_matrix, penalty_factor, alpha, beta, gamma)\n",
    "    stack = []\n",
    "    for i in range(bs):\n",
    "        stack.append(pf)\n",
    "    pm = torch.stack(stack, dim=0)\n",
    "    return pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = penalty_matrix(bs)\n",
    "pm = pm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.subplot(221)\n",
    "#plt.imshow(pm[0])#[136].reshape(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path.home()/'Luiz/saved_models/AROB'\n",
    "net = load_learner(model_dir/'ARViT2D-Base_6layers.pkl', cpu=False)\n",
    "weights_dir = model_dir/'best/ARViT2D-Base_6layers.pth'\n",
    "model = net.model\n",
    "#model.load_state_dict(torch.load(weights_dir))\n",
    "weights_dict = load_learner(weights_dir, cpu=False)\n",
    "model.load_state_dict(weights_dict)\n",
    "#model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "im = Image.open('sample_images/image'+str(10)+'.jpeg')\n",
    "img = transform(im).unsqueeze(0).to(device)\n",
    "outputs, attn, sattn, gm  = model(img.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "for i in range(8):\n",
    "    stack.append(gm)\n",
    "gm2 = torch.stack(stack, dim=0).reshape(8,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pm.shape[0]>=gm2.shape[0]:\n",
    "    pm = pm[:gm2.shape[0]] \n",
    "    print(pm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sattn[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pm*gm2\n",
    "dist_loss = torch.sum(loss)#.float().mean()\n",
    "dist_loss[dist_loss <= 1] = 1\n",
    "torch.log(dist_loss)\n",
    "#dist_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(221)\n",
    "plt.imshow(pm[0].cpu().detach().numpy())#[136].reshape(16,16))\n",
    "plt.subplot(222)\n",
    "plt.imshow(gm2[0].cpu().detach().numpy())#[136].reshape(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARViT_Loss = ARViT2D_Loss(bs,layer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = untar_data(URLs.IMAGENETTE)\n",
    "def data_loader(path):\n",
    "    transform = ([*aug_transforms(),Normalize.from_stats([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    data = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "                     get_items=get_image_files, \n",
    "                     splitter=RandomSplitter(),\n",
    "                     get_y=parent_label,\n",
    "                     item_tfms=Resize(H,W),\n",
    "                     batch_tfms=transform)\n",
    "\n",
    "    dloader = data.dataloaders(path,bs=bs)\n",
    "    return dloader\n",
    "dloader =  data_loader(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_head(model, n_classes):\n",
    "    model.head = nn.Linear(516, n_classes)\n",
    "    #model.noise_mode = True\n",
    "    #model.generator_mode = False\n",
    "\n",
    "    #trainable = ['head.weight','head.bias']\n",
    "    #for name, p in model.named_parameters():\n",
    "    #    if name not in trainable:\n",
    "    #        p.requires_grad = False\n",
    "    #    else:\n",
    "    #        p.requires_grad = True\n",
    "model_head(model,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(dloader, model, loss_func=ARViT_Loss, metrics=[Accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(1,0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
