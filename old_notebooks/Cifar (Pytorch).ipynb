{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.distributed import *\n",
    "from fastai.data import load\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "from fastprogress import fastprogress\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import argparse\n",
    "from models.utils.joiner2 import Joiner\n",
    "from models.utils.new_losses import *\n",
    "from models.utils.metrics import Accuracy, Curating_Of_Attention_Loss\n",
    "from models.utils.dataLoader import *\n",
    "from models.utils.datasets import *\n",
    "import webdataset as wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\n",
    "\n",
    "#train_path  = \"data/WebDataset-GramCifar/train/GramCifar-{0..4}.tar\"\n",
    "#valid_path = \"data/WebDataset-GramCifar/valid/GramCifar-0.tar\"\n",
    "\n",
    "H = 32\n",
    "W= 32\n",
    "bs = 5\n",
    "grid_l = 2\n",
    "nclass = 10\n",
    "backbone = False\n",
    "epochs = 5\n",
    "\n",
    "beta = 0.00005\n",
    "gamma = 0.0005\n",
    "sigma = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Loading the DataSets\n",
    "train_ds = datasets.CIFAR10(root='./data', train=True, download=True, transform=ds_transform())\n",
    "valid_ds = datasets.CIFAR10(root='./data', train=False, download=True, transform=ds_transform())\n",
    "#print(len(train_ds))\n",
    "#print(len(valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=bs)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size = bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Loss Functions\n",
    "train_loss = SingleLabelCriticLoss()\n",
    "valid_loss = SingleLabelCriticLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "model = Joiner(num_encoder_layers = 6, nhead=6, backbone = backbone, num_classes = nclass, bypass=False, pos_enc = \"sin\", hidden_dim=768, \n",
    "batch_size=bs, image_h=H, image_w=W, grid_l=grid_l,penalty_factor=\"1\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the optimizer and the Learning Rate decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 2e-7)\n",
    "model_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=9, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n",
      "Batch: 10000Epoch training complete in 23m 55s\n",
      "training loss: 0.3806, acc 0.1428\n",
      "validation loss: 0.3745, validation acc 0.0002 \n",
      "Epoch 2/5\n",
      "----------\n",
      "Batch: 10000Epoch training complete in 23m 56s\n",
      "training loss: 0.3681, acc 0.1485\n",
      "validation loss: 0.3635, validation acc 0.0002 \n",
      "Epoch 3/5\n",
      "----------\n",
      "Batch: 10000Epoch training complete in 23m 49s\n",
      "training loss: 0.3586, acc 0.1552\n",
      "validation loss: 0.3534, validation acc 0.0000 \n",
      "Epoch 4/5\n",
      "----------\n",
      "Batch: 6709"
     ]
    }
   ],
   "source": [
    "#THE TRAINING LOOP\n",
    "# model outputs -> [x, sattn, pattn, inputs, x0]\n",
    "\n",
    "running_loss_history = [] # training loss - to generate a plot\n",
    "running_acc_history = [] # traning accuracy\n",
    "#running_latt_history = [] # traning accuracy\n",
    "\n",
    "val_running_loss_history = [] # validation loss\n",
    "val_running_acc_history = [] # validation accuracy\n",
    "\n",
    "for e in range(epochs):\n",
    "  \n",
    "    start_time = time.time()\n",
    "    print('Epoch {}/{}'.format(e+1, epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    running_latt = 0.0\n",
    "    \n",
    "    val_running_loss = 0.0\n",
    "    val_running_acc = 0.0\n",
    "    \n",
    "    batch=0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        batch+=1\n",
    "        sys.stdout.write('\\rBatch: %d' %batch)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        #TRAINING\n",
    "        inputs = inputs.to(device) # allow gpu use\n",
    "        labels = labels.to(device)\n",
    "        #labels[0] = labels[0].to(device)\n",
    "        #labels[1] = labels[1].to(device)# allow gpu use\n",
    "        outputs = model(inputs) #gives the output of the last layer\n",
    "        loss = train_loss(outputs, labels) # comparing outputs and labels using the criteria\n",
    "        \n",
    "        optimizer.zero_grad() #zero the grad\n",
    "        loss.backward() #backpropagation\n",
    "        optimizer.step() #optimize weights \n",
    "\n",
    "        #COMPUTING TRAINING METRICS\n",
    "        acc = Accuracy(outputs,labels)\n",
    "        #latt = Curating_Of_Attention_Loss(outputs,labels)\n",
    "        \n",
    "        running_loss += loss.item() # the sum of the loss of all itens\n",
    "        running_acc += acc\n",
    "        #running_latt += latt\n",
    "        \n",
    "        Typenone = 0\n",
    "        zeros = 0\n",
    "        normal = 0\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad == None:\n",
    "                Typenone +=1\n",
    "            elif torch.sum(param.grad) == 0:\n",
    "                zeros += 1\n",
    "            else:\n",
    "                normal += 1\n",
    "        if Typenone >10:\n",
    "            print(\"None parameters:\",Typenone)\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad == None:\n",
    "                    print(name)\n",
    "        if zeros > 5:\n",
    "            print(\"Zero Grad Parameters:\", zeros)\n",
    "        #print(\"Normally computed Parameters:\",normal)\n",
    "                \n",
    "                \n",
    "    else:\n",
    "        #VALIDATION\n",
    "        with torch.no_grad(): # to save memory (temporalely set all the requires grad to be false)\n",
    "            for val_inputs, val_labels in valid_loader:\n",
    "                val_inputs = val_inputs.to(device) # allow gpu use\n",
    "                val_labels = val_labels.to(device) # allow gpu use\n",
    "                val_outputs = model(val_inputs) #passes the image through the network and get the output\n",
    "                val_loss = valid_loss(val_outputs, val_labels) #compare output and labels to get the loss \n",
    "\n",
    "                val_acc = Accuracy(val_outputs,val_labels)\n",
    "                val_running_loss += val_loss.item() #same as for training\n",
    "                val_running_acc += val_acc\n",
    "                \n",
    "    #Adding one step to the optimizer            \n",
    "    model_lr_scheduler.step()\n",
    "    \n",
    "    #TRAINING LOSS AND ACCURACY\n",
    "    epoch_loss = running_loss/len(train_ds) # the sum of the loss of all itens divided by the number of itens\n",
    "    epoch_acc = running_acc/len(train_loader) # the sum of correct predictions divided by the number of itens\n",
    "    #epoch_latt = running_latt/len(train_loader)\n",
    "    \n",
    "    running_loss_history.append(epoch_loss) #append to respective list\n",
    "    running_acc_history.append(epoch_acc) #append to respective list\n",
    "    #running_latt_history.append(epoch_latt) #append to respective list\n",
    "\n",
    "    #VALIDATION LOSS AND ACCURACY\n",
    "    val_epoch_loss = val_running_loss/len(valid_ds)\n",
    "    val_epoch_acc = val_acc/ len(valid_loader)\n",
    "    \n",
    "    val_running_loss_history.append(val_epoch_loss) #append to respective list\n",
    "    val_running_acc_history.append(val_epoch_acc) #append to respective list\n",
    "    \n",
    "    \n",
    "    epoch_time_elapsed = time.time() - start_time\n",
    "    print('Epoch training complete in {:.0f}m {:.0f}s'.format(\n",
    "            epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n",
    "    print('training loss: {:.4f}, acc {:.4f}'.format(epoch_loss, epoch_acc.item()))\n",
    "    print('validation loss: {:.4f}, validation acc {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
