{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.vision.gan import *\n",
    "from fastai.distributed import *\n",
    "from fastai.metrics import error_rate\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "import torch \n",
    "from fastai.metrics import *\n",
    "\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms.functional import *\n",
    "\n",
    "from collections import defaultdict, deque\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets.imagenet import ImageNet\n",
    "\n",
    "import random\n",
    "\n",
    "from skimage import io\n",
    "from PIL import *\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 32\n",
    "W= 32\n",
    "bs=5\n",
    "\n",
    "transform = T.Compose([\n",
    "T.Resize((H,W)),\n",
    "T.ToTensor(),\n",
    "T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Curating_of_attention_mask(nn.Module):\n",
    "    def __init__(self, width=32, height=32, grid_l=2):\n",
    "        super().__init__()\n",
    "        self.grid_l = grid_l\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.grids_list = self.grids_list(self.width, self.height, self.grid_l)\n",
    "        self.grids_matrix = self.grids_matrix(self.width, self.height, self.grid_l)\n",
    "        \n",
    "        \n",
    "    def grids_list(self, width, height, grid_l): #COMPUTED ONCE BEFORE TRAINING\n",
    "        w = width\n",
    "        h = height\n",
    "        qt_hor_grids = w//grid_l\n",
    "        qt_ver_grids = h//grid_l\n",
    "        qtd_grids = qt_hor_grids*qt_ver_grids\n",
    "        c = 0\n",
    "        grids_list = []\n",
    "        for i in range(qtd_grids):\n",
    "            hor_pos = i//qt_hor_grids\n",
    "            ver_pos = c\n",
    "            c = c+1\n",
    "            grid = [hor_pos,ver_pos]\n",
    "            grids_list.append(grid)\n",
    "            if c == qt_ver_grids:\n",
    "                c=0\n",
    "        return grids_list\n",
    "        \n",
    "        \n",
    "    def grids_matrix(self, width, height, grid_l):\n",
    "\n",
    "        w = width\n",
    "        h = height\n",
    "        len_input_seq = h*w\n",
    "        qt_hor_grids = w//grid_l\n",
    "        qt_ver_grids = h//grid_l\n",
    "\n",
    "\n",
    "        grid_list = []\n",
    "        for i in range(h):\n",
    "            row_grid_list = []\n",
    "            preliminar_ver_grid = i//grid_l\n",
    "            if preliminar_ver_grid != 0:\n",
    "                preliminar_ver_grid = preliminar_ver_grid*qt_hor_grids\n",
    "\n",
    "            for h in range(w):\n",
    "                preliminar_grid = h//grid_l+preliminar_ver_grid\n",
    "                row_grid_list.append(preliminar_grid)\n",
    "\n",
    "            grid_list.append(row_grid_list)\n",
    "        grid_matrix = torch.tensor(np.array(grid_list))\n",
    "\n",
    "        return grid_matrix\n",
    "        \n",
    "        \n",
    "    def img_patches(self, batch, grid_l):\n",
    "        #torch.Tensor.unfold(dimension, size, step)\n",
    "        #slices the images into grid_l*grid_l size patches\n",
    "        patches = batch.data.unfold(1, 3, 3).unfold(2, grid_l, grid_l).unfold(3, grid_l, grid_l)\n",
    "        a, b, c, d, e, f, g = patches.shape\n",
    "        patches = patches.reshape(a, c, d, e, f, g)\n",
    "        #print(patches.shape)\n",
    "        return patches\n",
    "\n",
    "\n",
    "    def grid_gram_matrix(self, patches):\n",
    "\n",
    "        a, b, c, d, e, f = patches.shape\n",
    "        # a=batch size\n",
    "        # b=horizontal patches\n",
    "        # c = vertical patches\n",
    "        # d=number of feature maps\n",
    "        # (e,f)=dimensions of a f. map (N=e*f)\n",
    "\n",
    "        features = patches.reshape(a * b * c, d, e*f)  # resise F_XL into \\hat F_XL\n",
    "        #print(features.shape)\n",
    "        # compute the gram product\n",
    "\n",
    "        G = torch.mm(features[0], features[0].t())\n",
    "\n",
    "        for i in range(1,a*b*c):\n",
    "            g = torch.mm(features[i], features[i].t())\n",
    "            G= torch.cat((G, g), 0)\n",
    "\n",
    "\n",
    "        G = G.div(d * e * f).reshape(a, b, c, d, d)\n",
    "\n",
    "        # we 'normalize' the values of the gram matrix\n",
    "        # by dividing by the number of element in each feature maps.\n",
    "\n",
    "        return G\n",
    "\n",
    "\n",
    "\n",
    "    def gram_dist_matrix(self, batch, grid_l):\n",
    "        patches = self.img_patches(batch, grid_l)\n",
    "        #print(patches.shape)\n",
    "        Grid = self.grid_gram_matrix(patches)\n",
    "        #print(Grid.shape)\n",
    "        bs = batch.shape[0]\n",
    "        #print(bs)\n",
    "        MSE = nn.MSELoss()\n",
    "\n",
    "        mse_grid = []\n",
    "        for k in range(bs):\n",
    "            dist_grid = []\n",
    "            for g in range(len(self.grids_list)):\n",
    "                dist_pair_list = []\n",
    "                for n in range(len(self.grids_list)):\n",
    "                    dist_pair_list.append(MSE(Grid[k][self.grids_list[g][0]][self.grids_list[g][1]], Grid[k][self.grids_list[n][0]][self.grids_list[n][1]]))\n",
    "                dist_grid.append(dist_pair_list)\n",
    "            mse_grid.append(dist_grid)\n",
    "\n",
    "        dist_matrix = torch.tensor(mse_grid)\n",
    "        #dist_matrix = torch.tensor(np.array(mse_grid))\n",
    "\n",
    "        for i in range(bs):\n",
    "            dist_matrix[i] = dist_matrix[i].view(dist_matrix[i].size(0), -1)\n",
    "            dist_matrix[i] -= dist_matrix[i].min(1, keepdim=True)[0]\n",
    "            dist_matrix[i] /= dist_matrix[i].max(1, keepdim=True)[0]\n",
    "            dist_matrix[i] = dist_matrix[i].view(1, len(self.grids_list), len(self.grids_list))\n",
    "\n",
    "        return dist_matrix\n",
    "\n",
    "\n",
    "    def penalty_factor(self, dist_matrix, penalty_factor=\"1\", alpha=1):\n",
    "        if penalty_factor == \"1\" or penalty_factor ==\"distraction\":\n",
    "            pf_matrix = ((dist_matrix+1))**alpha\n",
    "            return pf_matrix\n",
    "        if penalty_factor == \"2\" or penalty_factor ==\"misdirection\":\n",
    "            pf_matrix = alpha*((torch.max(dist_matrix)//2)-dist_matrix+0.1)**3\n",
    "            return pf_matrix\n",
    "\n",
    "\n",
    "    def penalty_matrix(self, width, height, grid_matrix, dist_matrix, grid_l):\n",
    "        bs,_,_ = dist_matrix.shape\n",
    "        pep = []\n",
    "        for s in range(bs):\n",
    "            pf_matrix = self.penalty_factor(dist_matrix[s], penalty_factor=\"1\", alpha=1)\n",
    "            w = width\n",
    "            h = height\n",
    "\n",
    "            qt_hor_grids = w//grid_l\n",
    "            qt_ver_grids = h//grid_l\n",
    "            qtd_grids = qt_hor_grids*qt_ver_grids\n",
    "\n",
    "            penalty_mask = []\n",
    "            for i in range(qtd_grids):\n",
    "                ref_column = pf_matrix[i]\n",
    "                p_matrix = grid_matrix.type(torch.FloatTensor)\n",
    "                for j in range(1,len(ref_column)):\n",
    "                    #print(float(j))\n",
    "                    p_matrix[p_matrix==j]=float(ref_column[j])\n",
    "                p_matrix[p_matrix==0]=float(ref_column[0])\n",
    "                penalty_mask.append(p_matrix)\n",
    "\n",
    "            #print(len(penalty_mask))    \n",
    "\n",
    "            penalty_enc = []\n",
    "            for i in range(h):\n",
    "                penalty_row = []\n",
    "                for j in range(w):\n",
    "                    #print(grid_matrix[i,j])\n",
    "                    #print(penalty_mask[grid_matrix[i,j]].shape)\n",
    "                    penalty_row.append(penalty_mask[grid_matrix[i,j]])\n",
    "                    #print(len(penalty_row))\n",
    "                generic_tensor = Tensor(h,w)\n",
    "                penalty_row_tensor = torch.cat(penalty_row, out=generic_tensor)\n",
    "                penalty_enc.append(penalty_row_tensor)\n",
    "                #print(penalty_row_tensor.shape)\n",
    "                #break\n",
    "\n",
    "            b = torch.Tensor(h, w, h, w)\n",
    "            c=torch.cat(penalty_enc, out=b)\n",
    "            c = c.view(h, w, h, w)\n",
    "            pep.append(c)\n",
    "\n",
    "        d = torch.Tensor(bs, h, w, h, w)\n",
    "        penalty_encoding_pattern = torch.cat(pep, out=d)\n",
    "        penalty_encoding_pattern = penalty_encoding_pattern.view(bs, h, w, h, w)\n",
    "\n",
    "        return penalty_encoding_pattern\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        batch = batch.unsqueeze(0)\n",
    "        \n",
    "        dist_matrix = self.gram_dist_matrix(batch, self.grid_l)\n",
    "        penalty_mask = self.penalty_matrix(self.width, self.height, self.grids_matrix, dist_matrix, self.grid_l)\n",
    "        \n",
    "        pattn = penalty_mask.squeeze(0)\n",
    "        \n",
    "        return pattn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCifar(datasets.CIFAR10):\n",
    "    def __init__(self, path, transforms, width=32, height=32, grid_l=2, size=None, train=True):\n",
    "        super().__init__(path)\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        if size == None:\n",
    "            if train == True:\n",
    "                self.size = 50000\n",
    "            else:\n",
    "                self.size = 10000\n",
    "        else:\n",
    "            self.size = size\n",
    "        self.indexes = self.create_idx()\n",
    "        self.attention_mask = Curating_of_attention_mask(width, height, grid_l)\n",
    "        self.pattn_dict = self.create_labels()\n",
    "\n",
    "    def create_idx(self):\n",
    "        indexes = {}\n",
    "        i = 0\n",
    "        max_len = 50000\n",
    "        if self.train != True:\n",
    "            max_len = 10000\n",
    "        while len(indexes) < (self.size):\n",
    "            r=random.randint(0,max_len)\n",
    "            if r not in indexes.values(): \n",
    "                indexes[i] = r\n",
    "                i +=1\n",
    "\n",
    "        return indexes\n",
    "    \n",
    "    def create_labels(self):\n",
    "        \n",
    "        transform = T.Compose([\n",
    "        T.Resize((self.height,self.width)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        attention_labels = {}\n",
    "        for i in range(len(self.indexes)):\n",
    "            index = self.indexes[i]\n",
    "            im, _ = super().__getitem__(index)\n",
    "            pattn = self.attention_mask(self.transforms(im))\n",
    "            attention_labels[i] = pattn\n",
    "\n",
    "        return attention_labels\n",
    "\n",
    "    def __len__(self):\n",
    "         return len(self.indexes)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #index = self.indexes[index]\n",
    "        im, label = super().__getitem__(self.indexes[index])\n",
    "        pattn = self.pattn_dict[index]\n",
    "        return self.transforms(im), (pattn, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CustomCifar(path='./data', transforms=transform, size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CustomCifar\n",
       "    Number of datapoints: 50\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    Compose(\n",
       "    Resize(size=(32, 32), interpolation=PIL.Image.BILINEAR)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ds, 'customCifar.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CifarDataloader(path_train, path_val=None): #\n",
    "    if path_val = None:\n",
    "        db = torch.load('customCifar.tar')\n",
    "        train_size = int(len(db)*0.8)\n",
    "        val_size = int(len(db)*0.2)\n",
    "        remainder = len(db)-train_size - val_size\n",
    "        train, valid, _ = torch.utils.data.random_split(Loaded_db, [train_size, val_size, remainder])\n",
    "        \n",
    "        train_dl = load.DataLoader(train,batch_size=5)\n",
    "        valid_dl = load.DataLoader(valid,batch_size=5)\n",
    "        dld = ImageDataLoaders(train_dl, valid_dl, device='cuda')\n",
    "        \n",
    "        return dld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loaded_db = torch.load('customCifar.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape torch.Size([3, 32, 32])\n",
      "Pattn shape torch.Size([32, 32, 32, 32])\n",
      "Label 1\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(\"Input shape\", Loaded_db[i][0].shape)\n",
    "print(\"Pattn shape\", Loaded_db[i][1][0].shape)\n",
    "print(\"Label\", Loaded_db[i][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Loaded_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(db)*0.8)\n",
    "int(len(db)*0.2)\n",
    "len(db)-int(len(db)*0.8)-int(51*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data import load\n",
    "dloader = load.DataLoader(dataset=Loaded_db, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader size: 50000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataloader size:\",len(dloader.data))\n",
    "#dloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 40\n",
    "test_size = 10\n",
    "remainder = 0\n",
    "train, valid, _ = torch.utils.data.random_split(Loaded_db, [train_size, test_size, remainder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = load.DataLoader(train,batch_size=5)\n",
    "valid_dl = load.DataLoader(valid,batch_size=5)\n",
    "dld = ImageDataLoaders(train_dl, valid_dl, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Curating_of_attention_loss(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    " \n",
    "    def forward(self, sattn, pattn):\n",
    "        #Computing the Attention Loss\n",
    "        att_loss = sattn*pattn\n",
    "        Latt = torch.sum(att_loss)\n",
    "\n",
    "        return Latt\n",
    "\n",
    "\n",
    "class CriticLoss(nn.Module):\n",
    "    def __init__(self, beta=0.0000005, sigma=1):\n",
    "        super(CriticLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, preds, label):\n",
    "        #print(\"Critic Loss\")\n",
    "        crossEntropy = nn.CrossEntropyLoss()\n",
    "        classificationLoss = crossEntropy(preds[0], label[1])\n",
    "\n",
    "        LCA = Curating_of_attention_loss()\n",
    "        Latt = LCA(preds[1], label[0])\n",
    "        \n",
    "        Lc = self.sigma*classificationLoss - self.beta*Latt\n",
    "        \n",
    "        return Lc\n",
    "    \n",
    "#[x, sattn, pattn, inputs, x0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils.joiner2 import Joiner\n",
    "#from models.utils.new_losses import CriticLoss\n",
    "from models.utils.metrics import Accuracy\n",
    "\n",
    "model = Joiner(num_encoder_layers = 6, nhead=8, backbone = False, num_classes = 10, bypass=False, hidden_dim=256, \n",
    "          batch_size=bs, image_h=H, image_w=W,grid_l=2,penalty_factor=\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_loss = CriticLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(dld, model, loss_func=critic_loss, metrics=[Accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=3.0199516913853586e-06, lr_steep=2.0892961401841603e-05)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "for i in range(1001):\n",
    "    if i%50 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
